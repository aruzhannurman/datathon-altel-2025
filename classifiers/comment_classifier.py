import os, sys, json, argparse
from openai import OpenAI

TARGET_LABELS = ["question", "review", "complaint", "gratitude"]
TONE_LABELS = ["negative", "neutral", "positive"]

from typing import Dict, List, Tuple
import torch
from transformers import AutoTokenizer, AutoModel

RUBERT_MODEL_ID = "cointegrated/rubert-tiny2"
LABELS_EN = ["question", "review", "complaint", "gratitude"]
TONES_EN = ["negative", "neutral", "positive"]

LABEL_DESCRIPTIONS_RU = {
    "question": "Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¿Ñ€Ð¾ÑÑŒÐ±Ð° Ð¿Ð¾ÑÑÐ½Ð¸Ñ‚ÑŒ, ÐºÐ°Ðº ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ",
    "review": "Ð¾Ñ‚Ð·Ñ‹Ð², Ð¾Ñ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°, Ð²Ð¿ÐµÑ‡Ð°Ñ‚Ð»ÐµÐ½Ð¸Ðµ Ð¾ ÑÐ²ÑÐ·Ð¸",
    "complaint": "Ð¶Ð°Ð»Ð¾Ð±Ð°, Ð¿Ñ€ÐµÑ‚ÐµÐ½Ð·Ð¸Ñ, Ð½ÐµÐ´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¾ Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹",
    "gratitude": "Ð±Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€Ð½Ð¾ÑÑ‚ÑŒ, ÑÐ¿Ð°ÑÐ¸Ð±Ð¾, Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°",
}

TONE_DESCRIPTIONS_RU = {
    "negative": "Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾Ð½, Ð¶Ð°Ð»Ð¾Ð±Ñ‹, Ð¿Ñ€ÐµÑ‚ÐµÐ½Ð·Ð¸Ð¸, Ð½ÐµÐ´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¾",
    "neutral": "Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾Ð½, Ð±ÐµÐ· ÑÑ€ÐºÐ¾ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐ¼Ð¾Ñ†Ð¸Ð¹",
    "positive": "Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ‚Ð¾Ð½, Ð¿Ð¾Ñ…Ð²Ð°Ð»Ð°, Ð±Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€Ð½Ð¾ÑÑ‚ÑŒ, Ð¾Ð´Ð¾Ð±Ñ€ÐµÐ½Ð¸Ðµ",
}

SYSTEM_PROMPT_TEMPLATE = """
You are a careful classifier of user comments.

Your task is to assign the comment to exactly one of the categories:
- "question"
- "review"
- "complaint"
- "gratitude"

Also assign the tone:
- "negative"
- "neutral"
- "positive"

Output ONLY valid JSON with schema:
{"label": one_of(["question","review","complaint","gratitude"]),
 "tone": one_of(["negative","neutral","positive"]),
 "confidence": 0..1,
 "reason": "short explanation"}

Here are some examples:

Example:
TEXT: "ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚?"
LABEL: question
TONE: neutral

Example:
TEXT: "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! ÐÐµÐ´ÐµÐ»ÑŽ Ð½Ð°Ð·Ð°Ð´ Ð·Ð°ÑÐ²ÐºÑƒ Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐ»! Ð˜ÑÑ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð·Ð²Ð¾Ð½ÐºÐ¸ Ð½Ðµ Ð¾ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð»ÑÑŽÑ‚ÑÑ, Ð½Ðµ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð·Ð²Ð¾Ð½Ð¸Ñ‚ÑŒ Ð´Ð°Ð¶Ðµ Ð² ÐšÐ°ÑÐ¿Ð¸Ð¹ Ð±Ð°Ð½Ðº? Ð§Ñ‚Ð¾ Ð·Ð° Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ñƒ Ð²Ð°Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°Ð¼, Ð² ÐºÐ¾Ð»Ð» Ñ†ÐµÐ½Ñ‚Ñ€ Ð½Ðµ Ð´Ð¾Ð·Ð²Ð¾Ð½Ð¸ÑˆÑŒÑÑ, ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÑŽÑ‚! Ð’ÑÐµ ÑÐ»Ð¾Ð¶Ð½Ð¾ Ñƒ Ð²Ð°Ñ, Ð½ÐµÑ‚ Ð½Ð¸ÐºÐ°ÐºÐ¾Ð¹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸, Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° Ð½ÑƒÐ»Ðµ ðŸ¥º"
LABEL: complaint
TONE: negative

Example:
TEXT: "Ð§Ñ‚Ð¾ Ð·Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚? Ð•Ð³Ð¾ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð½ÐµÑ‚. ÐŸÑ€Ð¾ÑÑ‚Ð¾ ÑƒÐ¶Ð°ÑÐ½Ð°Ñ ÑÐ²ÑÐ·ÑŒ!!!"
LABEL: complaint
TONE: negative

Example:
TEXT: "ÐÐ¸ Ð² ÐºÐ¾ÐµÐ¼ ÑÐ»ÑƒÑ‡Ð°Ðµ Ð½Ðµ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ð¹Ñ‚Ðµ ÑÑ‚Ñƒ ÑÐ²ÑÐ·ÑŒ, ÑÐ°Ð¼Ð°Ñ Ñ…ÑƒÐ´ÑˆÐ°Ñ ÑÐ²ÑÐ·ÑŒðŸ‘ŽðŸ‘ŽðŸ‘Ž"
LABEL: complaint
TONE: negative

Example:
TEXT: "ÐŸÐ¾Ð»ÑŒÐ·ÑƒÑŽÑÑŒ Altel ÑƒÐ¶Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð»ÐµÑ‚ â€” Ð²ÑÐµÐ³Ð´Ð° ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð°Ñ ÑÐ²ÑÐ·ÑŒ Ð¸ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚! ðŸ‘"
LABEL: review
TONE: positive

Example:
TEXT: "ÐžÑ‡ÐµÐ½ÑŒ Ð´Ð¾Ð²Ð¾Ð»ÐµÐ½ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼ Altel: Ñ‚Ð°Ñ€Ð¸Ñ„Ñ‹ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ, Ð° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ²ÑÐ·Ð¸ Ð½Ð° Ð²Ñ‹ÑÐ¾Ñ‚Ðµ ðŸ’¯"
LABEL: review
TONE: positive

Example:
TEXT: "Altel Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð¾ ÑƒÐ´Ð¸Ð²Ð¸Ð» â€” Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ðµ, ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸ÐºÐ¸ Ð²ÑÐµÐ³Ð´Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÑŽÑ‚, Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾ ðŸ˜Š"
LABEL: review
TONE: positive

Example:
TEXT: "Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Altel Ð·Ð° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½ÑƒÑŽ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ, Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ ÑƒÑÐ»ÑƒÐ³Ð°Ð¼Ð¸!"
LABEL: gratitude
TONE: positive

Example:
TEXT: "ÐšÐ°Ðº Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ‚Ð°Ñ€Ð¸Ñ„ Altel Ð¸ Ð¼Ð¾Ð¶Ð½Ð¾ Ð»Ð¸ ÑÑ‚Ð¾ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ð¾Ð½Ð»Ð°Ð¹Ð½?"
LABEL: question
TONE: neutral

Example:
TEXT: "Ð‘Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€ÑŽ Ð·Ð° Ð±Ñ‹ÑÑ‚Ñ€ÑƒÑŽ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ Ð² ÐºÐ¾Ð»Ð»-Ñ†ÐµÐ½Ñ‚Ñ€Ðµ, Ñ€ÐµÑˆÐ¸Ð»Ð¸ Ð¼Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð·Ð° Ð¿Ð°Ñ€Ñƒ Ð¼Ð¸Ð½ÑƒÑ‚ ðŸ™"
LABEL: gratitude
TONE: positive

Example:
TEXT: "ÐŸÐ¾Ð´ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, ÐºÐ°Ðº Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ðº Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð° Ð¿Ð¾ Ð¼Ð¾ÐµÐ¼Ñƒ Ñ‚Ð°Ñ€Ð¸Ñ„Ñƒ?"
LABEL: question
TONE: neutral

Example:
TEXT: "Altel Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€, ÑÐ²ÑÐ·ÑŒ Ð»Ð¾Ð²Ð¸Ñ‚ Ð´Ð°Ð¶Ðµ Ñ‚Ð°Ð¼, Ð³Ð´Ðµ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚!"
LABEL: review
TONE: positive

Example:
TEXT: "ÐÐ»Ñ‚ÐµÐ» Ñ‚Ð¾Ð¿Ñ‡Ð¸Ðº, Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð»ÐµÑ‚Ð°ÐµÑ‚ ðŸ”¥"
LABEL: review
TONE: positive

Example:
TEXT: "Ð­Ð¹, Ñƒ ÐºÐ¾Ð³Ð¾ ÐµÑ‰Ñ‘ ÑÐµÑ‚ÑŒ Ñ‚ÑƒÐ¿Ð¸Ñ‚? Ð£Ð¶Ðµ Ñ‡Ð°Ñ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð½Ðµ Ð»Ð¾Ð²Ð¸Ñ‚ ðŸ˜¡"
LABEL: complaint
TONE: negative

Example:
TEXT: "Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ, Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð²Ð¸Ð´Ð¾ÑÑ‹ Ð³Ñ€ÑƒÐ·ÑÑ‚ÑÑ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ ðŸ™Œ"
LABEL: gratitude
TONE: positive

Example:
TEXT: "ÐÐ»Ñ‚ÐµÐ», Ð½Ñƒ ÐºÐ°Ðº Ñ‚Ð°Ðº? ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ñƒ Ð¼ÐµÐ½Ñ Ð¾Ð¿ÑÑ‚ÑŒ Ð¼Ð¸Ð½ÑƒÑ Ð±Ð°Ð»Ð°Ð½Ñ? ðŸ¤”"
LABEL: question
TONE: negative

Example:
TEXT: "ÐšÑÑ‚Ð°Ñ‚Ð¸, ÑÐ²ÑÐ·ÑŒ Ñƒ Ð²Ð°Ñ Ð»ÑƒÑ‡ÑˆÐµ, Ñ‡ÐµÐ¼ Ñƒ Ð¼Ð½Ð¾Ð³Ð¸Ñ… ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð², Ñ€ÐµÑÐ¿ÐµÐºÑ‚ ðŸ‘"
LABEL: review
TONE: positive

Example:
TEXT: "Ðž, ÐºÐ»Ð°ÑÑ, Ð¾Ð¿ÑÑ‚ÑŒ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð° Ð½ÐµÑ‚â€¦ ÑÐ¿Ð°ÑÐ¸Ð±Ð¾, Altel, Ð²ÑÐµÐ³Ð´Ð° Ð²Ð¾Ð²Ñ€ÐµÐ¼Ñ ðŸ‘"
LABEL: complaint
TONE: negative

Example:
TEXT: "Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ ÑÐµÑ€Ð²Ð¸Ñ! Ð§Ñ‚Ð¾Ð±Ñ‹ Ð´Ð¾Ð·Ð²Ð¾Ð½Ð¸Ñ‚ÑŒÑÑ Ð² Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÑƒ, Ð½ÑƒÐ¶Ð½Ð¾ Ð¸Ð¼ÐµÑ‚ÑŒ Ñ†ÐµÐ»Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ðŸ˜‚"
LABEL: complaint
TONE: negative

Example:
TEXT: "Altel, Ð²Ñ‹ Ð³ÐµÐ½Ð¸Ð¸! Ð‘Ð°Ð»Ð°Ð½Ñ Ð¸ÑÑ‡ÐµÐ·Ð°ÐµÑ‚ Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ, Ñ‡ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ ðŸ¤¡"
LABEL: complaint
TONE: negative

Example:
TEXT: "ÐžÐ³Ð¾, Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð²ÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ! Ð—Ð°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÑÑ‚Ð¾Ñ‚ Ð´ÐµÐ½ÑŒ Ð² ÐºÐ°Ð»ÐµÐ½Ð´Ð°Ñ€ÑŒ ðŸŽ‰"
LABEL: review
TONE: negative

Example:
TEXT: "ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ñ‚Ð°ÐºÐ°Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð°Ñ, Ñ‡Ñ‚Ð¾ Ñ ÑƒÐ¶Ðµ ÑÐ¾ÑÑ‚Ð°Ñ€Ð¸Ð»ÑÑ, Ð¿Ð¾ÐºÐ° Ð¶Ð´Ð°Ð» Ð¾Ñ‚Ð²ÐµÑ‚Ð° ðŸ™„"
LABEL: complaint
TONE: negative

Example:
TEXT: "Ð¡Ð¾Ð·Ð´Ð°Ð»Ð¸ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ Ñ‡Ñ‚Ð¾ Ð´Ð¾ Ð’Ð°Ñ Ð½Ð¸ÐºÐ°ÐºÐ¸Ð¼ ÐºÐ°Ð½Ð°Ð»Ð¾Ð¼ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÑ‡Ð°Ñ‚ÑŒÑÑ Ð¸ ÐµÑ‰Ðµ Ð¾Ñ‚Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÐµÑÑŒ ÐºÐ°Ðº Ð²ÑÐµ ÐºÑ€ÑƒÑ‚Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð¸ Ð¸ Ð·Ð° ÑÑ‚Ð¾ Ð±Ð¾Ð½ÑƒÑÑ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚Ðµ"
LABEL: complaint
TONE: negative

Example:
TEXT: "@altel_kz Ð²Ñ‹ Ð¸Ð·Ð´ÐµÐ²Ð°ÐµÑ‚ÐµÑÑŒ, Ð´Ð°?! Ð”Ð¾ Ð²Ð°Ñ Ð½Ðµ Ð´Ð¾Ð·Ð²Ð¾Ð½Ð¸Ñ‚ÑŒÑÑ, Ñ€Ð¾ÑƒÑ‚ÐµÑ€ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð½Ð° 5 Ð´Ð¶Ð¸, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 4 Ð´Ð¶Ð¸, ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ñ€Ð½Ð¾ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ Ð²Ð°Ñ‚ÑÐ°Ð¿ Ð½Ðµ Ð¼Ð¾Ð³Ñƒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ !!! Ð‘ÐµÑÐ¿Ñ€ÐµÐ´ÐµÐ» Ð¿Ð¾Ð»Ð½ÐµÐ¹ÑˆÐ¸Ð¹, Ð² ÐºÐ¾Ð»Ð» Ñ†ÐµÐ½Ñ‚Ñ€ Ðº Ð²Ð°Ð¼ Ð½Ðµ Ð´Ð¾Ð·Ð²Ð¾Ð½Ð¸Ñ‚ÑŒÑÑ!!!"
LABEL: complaint
TONE: negative

Example:
TEXT: "Ð¡Ð°Ð¼Ñ‹Ð¹ Ð¾Ñ‚Ð²Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÐµÑ€Ð²Ð¸Ñ Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð². Ð”Ð¾Ð·Ð²Ð¾Ð½Ð¸Ñ‚ÑÑ Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð±ÐµÑÐ¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð±Ð¾Ñ‚ Ð² Ð¢ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼, Ð½ÐµÐ¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ðµ Ð¾Ð±Ð¼Ð°Ð½Ð½Ñ‹Ðµ Ð°ÐºÑ†Ð¸Ð¸. Ð Ð°Ð·Ð¾Ñ‡Ð°Ñ€Ð¾Ð²Ð°Ð½. ÐŸÐ¾ÑÐ»Ðµ 15 Ð»ÐµÑ‚ Ð±ÑƒÐ´Ñƒ Ð¼ÐµÐ½ÑÑ‚ÑŒ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€. @altel_kz - Ñ€Ð°Ð·Ð¾Ñ‡Ð°Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"
LABEL: complaint
TONE: negative

Example:
TEXT: "ÐÐ»Ñ‚ÐµÐ» ÑÑ‚Ð¾ Ð½Ðµ ÑÐ²ÑÐ·ÑŒ Ð° Ð±ÐµÐ´Ð° ÐºÐ°ÐºÐ°Ñ Ñ‚Ð¾"
LABEL: review
TONE: negative

Example:
TEXT: "ÒšÐ°Ð»Ð°Ð¹ Ñ‚Ð°Ñ€Ð¸Ñ„Ñ–Ð¼ Ð±Ñ–Ñ‚ÐµÐ´Ñ– Ð½Ð¾Ð¼ÐµÑ€Ð´Ñ– Ð¼ÑƒÑÐ¾Ñ€Ò“Ð° Ð»Ð°Ò›Ñ‚Ñ‹Ñ€Ð°Ð¼, Ð¾Ñ€Ð½Ñ‹ ÑÐ¾Ð» Ð¶ÐµÑ€Ð´Ðµ, Ð±Ð¸Ð»Ð°Ð¹Ð½Ò“Ð° ÐºÓ©ÑˆÐµÐ¼"
LABEL: review
TONE: negative

Example:
TEXT: "ÒšÐ°Ð»Ð°Ð¹ Ñ‚Ð°Ñ€Ð¸Ñ„Ñ–Ð¼ Ð±Ñ–Ñ‚ÐµÐ´Ñ– Ð½Ð¾Ð¼ÐµÑ€Ð´Ñ– Ð¼ÑƒÑÐ¾Ñ€Ò“Ð° Ð»Ð°Ò›Ñ‚Ñ‹Ñ€Ð°Ð¼, Ð¾Ñ€Ð½Ñ‹ ÑÐ¾Ð» Ð¶ÐµÑ€Ð´Ðµ, Ð±Ð¸Ð»Ð°Ð¹Ð½Ò“Ð° ÐºÓ©ÑˆÐµÐ¼"
LABEL: review
TONE: negative

Example:
TEXT: "ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ñƒ Ð²Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ñ‚ÑƒÐ¿Ð°Ñ"
LABEL: question
TONE: negative

Example:
TEXT: "Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ò›Ð°ÑˆÐ°Ð½ Ð´Ò±Ñ€Ñ‹Ñ Ð¶Ð°ÑÐ°Ð¹Ð´Ñ‹ Ð¼Ò¯Ð»Ð´Ðµ ÑÐµÑ‚ÑŒ Ð¶Ð¾Ò›"
LABEL: complaint
TONE: negative

Example:
TEXT: "ÐžÑ‚Ð²Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ðº Ð°Ð±Ð¾Ñ€Ð¸Ð³ÐµÐ½Ð°Ð¼!
ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚, Ð° Ð¾Ð¿Ð»Ð°Ñ‚Ð° Ð·Ð° Ñ‚Ð°Ñ€Ð¸Ñ„ ÑÐ½Ð¸Ð¼Ð°ÐµÑ‚ÑÑ Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ð¾.
Ð”Ð¾Ð·Ð²Ð¾Ð½Ð¸Ñ‚ÑŒÑÑ Ð½Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾.
ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ Ð²Ñ‹ Ñ‚ÐµÑ€ÑÐµÑ‚Ðµ ÑÐ²Ð¾Ð¸Ñ… Ð°Ð±Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð² Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸ÐµÐ¼.
Ð‘Ð»Ð°Ð³Ð¾ ÐµÑÑ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñ‹ ÑÐ¾Ñ‚Ð¾Ð²Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸. Ð£Ð´Ð°Ñ‡Ð¸"
LABEL: complaint
TONE: negative


---

Now classify this new comment:
TEXT: "{text}"
"""


def build_prompt(text: str) -> str:
    # We only need to format the template with the current input text
    return SYSTEM_PROMPT_TEMPLATE.replace("{text}", text)


def classify_comment(
    text: str,
    model: str = "gpt-4o-mini-2024-07-18",
    temperature: float = 0.0,
    max_retries: int = 1,
) -> dict:
    client = OpenAI()
    messages = [{"role": "system", "content": build_prompt(text)}]

    last_err = None
    for _ in range(max_retries + 1):
        try:
            resp = client.chat.completions.create(
                model=model, temperature=temperature, messages=messages
            )
            raw = resp.choices[0].message.content.strip()
            try:
                obj = json.loads(raw)
                if obj.get("label") in TARGET_LABELS and obj.get("tone") in TONE_LABELS:
                    return obj
                last_err = f"Validation failed: {raw}"
            except json.JSONDecodeError as e:
                last_err = f"JSON parse error: {e}"
        except Exception as e:
            last_err = f"OpenAI API error: {e}"
    raise ValueError(f"Failed to obtain valid JSON. Last error: {last_err}")


_rubert = None
_rubert_tok = None


def _load_rubert() -> Tuple[AutoTokenizer, AutoModel]:
    global _rubert, _rubert_tok
    if _rubert is None:
        _rubert_tok = AutoTokenizer.from_pretrained(RUBERT_MODEL_ID)
        _rubert = AutoModel.from_pretrained(RUBERT_MODEL_ID)
        _rubert.eval()
    return _rubert_tok, _rubert


@torch.no_grad()
def _mean_pool(
    last_hidden_state: torch.Tensor, attention_mask: torch.Tensor
) -> torch.Tensor:
    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()
    summed = (last_hidden_state * mask).sum(dim=1)
    counts = mask.sum(dim=1).clamp(min=1e-9)
    return summed / counts


@torch.no_grad()
def _embed(texts: List[str]) -> torch.Tensor:
    tok, mdl = _load_rubert()
    enc = tok(texts, padding=True, truncation=True, max_length=256, return_tensors="pt")
    out = mdl(**enc)
    emb = _mean_pool(out.last_hidden_state, enc["attention_mask"])
    emb = torch.nn.functional.normalize(emb, p=2, dim=1)  # cosine
    return emb


def _softmax(x: torch.Tensor) -> torch.Tensor:
    x = x - x.max()
    return torch.softmax(x, dim=-1)


def classify_with_rubert(text: str) -> Dict:
    """Zero-shot-ish: cosine similarity between text and RU descriptions for labels & tones."""
    label_candidates = [LABEL_DESCRIPTIONS_RU[k] for k in LABELS_EN]
    tone_candidates = [TONE_DESCRIPTIONS_RU[k] for k in TONES_EN]
    embs = _embed([text] + label_candidates + tone_candidates)

    q = embs[0:1]
    label_mat = embs[1 : 1 + len(LABELS_EN)]
    tone_mat = embs[1 + len(LABELS_EN) :]

    sim_labels = (q @ label_mat.T).squeeze(0)  # (4,)
    sim_tones = (q @ tone_mat.T).squeeze(0)  # (3,)

    p_labels = _softmax(sim_labels)
    p_tones = _softmax(sim_tones)

    li = int(torch.argmax(p_labels))
    ti = int(torch.argmax(p_tones))

    label = LABELS_EN[li]
    tone = TONES_EN[ti]
    # Combine heads conservatively (geometric mean)
    conf = float(torch.sqrt(p_labels[li] * p_tones[ti]).item())

    return {
        "label": label,
        "tone": tone,
        "confidence": round(conf, 3),
        "reason": (
            f"RuBERT-tiny2 cosine similarity: "
            f"label={label} (pâ‰ˆ{float(p_labels[li]):.2f}), "
            f"tone={tone} (pâ‰ˆ{float(p_tones[ti]):.2f})"
        ),
    }


def classify_comment_with_verification(
    text: str,
    model: str = "gpt-4o-mini-2024-07-18",
    strict: bool = False,
    margin: float = 0.20,
) -> Dict:
    llm_res = classify_comment(text, model=model)  # your existing LLM function
    rubert_res = classify_with_rubert(text)
    return reconcile_predictions(llm_res, rubert_res, strict=strict, margin=margin)


def reconcile_predictions(
    llm_res: Dict, rubert_res: Dict, strict: bool = False, margin: float = 0.20
) -> Dict:
    """
    Combine LLM (primary) with RuBERT (verification).

    - If both agree -> final = that label/tone; confidence = max(LLM, RuBERT).
    - If disagree:
        * default (strict=False): keep LLM, lower confidence slightly, note discrepancy.
        * strict=True: RuBERT may override if (rubert_conf - llm_conf) >= margin.
    """
    out = {
        "label_llm": llm_res.get("label"),
        "tone_llm": llm_res.get("tone"),
        "confidence_llm": float(llm_res.get("confidence", 0.0)),
        "label_rubert": rubert_res.get("label"),
        "tone_rubert": rubert_res.get("tone"),
        "confidence_rubert": float(rubert_res.get("confidence", 0.0)),
    }

    agree_label = out["label_llm"] == out["label_rubert"]
    agree_tone = out["tone_llm"] == out["tone_rubert"]
    out["agree_label"] = agree_label
    out["agree_tone"] = agree_tone

    # Default: keep LLM
    final_label = out["label_llm"]
    final_tone = out["tone_llm"]
    final_conf = out["confidence_llm"]
    reason = "LLM primary."

    if agree_label and agree_tone:
        final_conf = max(out["confidence_llm"], out["confidence_rubert"])
        reason = "LLM & RuBERT agree."
    else:
        if strict and (out["confidence_rubert"] - out["confidence_llm"] >= margin):
            final_label = out["label_rubert"]
            final_tone = out["tone_rubert"]
            final_conf = out["confidence_rubert"]
            reason = f"RuBERT override (margin â‰¥ {margin})."
        else:
            # keep LLM but discount a bit for disagreement
            final_conf = max(0.0, final_conf - 0.1)
            reason = "Disagreement: kept LLM; discounted confidence."

    out["final_label"] = final_label
    out["final_tone"] = final_tone
    out["final_confidence"] = round(final_conf, 3)
    out["reason"] = reason
    return out


def main():
    ap = argparse.ArgumentParser(
        description="Classify a comment: label (question/review/complaint/gratitude) + tone (negative/neutral/positive)"
    )
    ap.add_argument("--text", type=str, help="Single comment text")
    ap.add_argument("--model", type=str, default="gpt-4o-mini-2024-07-18")
    ap.add_argument(
        "--verify", action="store_true", help="Run RuBERT-tiny2 verification after LLM"
    )
    ap.add_argument(
        "--strict",
        action="store_true",
        help="Allow RuBERT to override LLM if much more confident",
    )
    ap.add_argument(
        "--margin",
        type=float,
        default=0.20,
        help="Confidence margin for strict override",
    )
    args = ap.parse_args()

    if args.text:
        if args.verify:
            res = classify_comment_with_verification(
                args.text, model=args.model, strict=args.strict, margin=args.margin
            )
        else:
            res = classify_comment(args.text, model=args.model)
        print(json.dumps(res, ensure_ascii=False, indent=2))
        return

    if not sys.stdin.isatty():
        text = sys.stdin.read().strip()
        if text:
            if args.verify:
                res = classify_comment_with_verification(
                    text, model=args.model, strict=args.strict, margin=args.margin
                )
            else:
                res = classify_comment(text, model=args.model)
            print(json.dumps(res, ensure_ascii=False, indent=2))
            return

    ap.print_help()


if __name__ == "__main__":
    main()
